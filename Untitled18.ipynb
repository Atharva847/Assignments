{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f017b-9c90-49aa-8402-39b3c6db4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1: What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "Lasso Regression (Least Absolute Shrinkage and Selection Operator) is a type of linear regression that includes a regularization term to \n",
    "prevent overfitting by adding a penalty proportional to the absolute values of the coefficients. This penalty term encourages the model to \n",
    "shrink some coefficients to exactly zero, effectively performing feature selection.\n",
    "\n",
    "Key Differences:\n",
    "\n",
    "Penalty Term: Lasso adds a penalty based on the sum of the absolute values of the coefficients (\n",
    "ğœ†\n",
    "âˆ‘\n",
    "ğ‘—\n",
    "=\n",
    "1\n",
    "ğ‘\n",
    "âˆ£\n",
    "ğ›½\n",
    "ğ‘—\n",
    "âˆ£\n",
    "Î»âˆ‘ \n",
    "j=1\n",
    "p\n",
    "â€‹\n",
    " âˆ£Î² \n",
    "j\n",
    "â€‹\n",
    " âˆ£), as opposed to Ridge Regression, which uses the sum of squared coefficients.\n",
    "Feature Selection: Lasso can perform feature selection by driving some coefficients to zero, eliminating less important features from the model.\n",
    "Shrinkage: Lasso shrinks the coefficients of the less significant predictors, whereas ordinary least squares (OLS) does not apply any shrinkage.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e517ece9-4872-4b35-9ede-325213fed0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q2: What is the main advantage of using Lasso Regression in feature selection?\n",
    "Main Advantage:\n",
    "\n",
    "Automatic Feature Selection: The primary advantage of Lasso Regression in feature selection is its ability to automatically select a subset of\n",
    "features by shrinking the coefficients of less important variables to exactly zero. This results in a more interpretable and simpler model, \n",
    "which can be particularly useful when dealing with high-dimensional datasets with many features.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6574e19-67d4-4dbb-8e8e-acfe104a1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q3: How do you interpret the coefficients of a Lasso Regression model?\n",
    "Interpreting Lasso Regression Coefficients:\n",
    "\n",
    "Magnitude and Significance: The non-zero coefficients in a Lasso regression model represent the variables that have a significant impact on the\n",
    "dependent variable. The magnitude of these coefficients indicates the strength of the relationship, while the sign (positive or negative) indicates \n",
    "the direction of the relationship.\n",
    "Zero Coefficients: Coefficients that are exactly zero indicate that the corresponding features have been excluded from the model, meaning they do not \n",
    "contribute significantly to the prediction of the dependent variable.\n",
    "Bias: Because of the regularization, the non-zero coefficients in Lasso are typically smaller than they would be in an OLS model, introducing bias to\n",
    "reduce variance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0997428-8455-4d54-ba53-05cb6fc465ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4: What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "Tuning Parameters:\n",
    "\n",
    "Lambda (\n",
    "ğœ†\n",
    "Î»): The primary tuning parameter in Lasso regression is \n",
    "ğœ†\n",
    "Î», which controls the strength of the regularization.\n",
    "\n",
    "Low \n",
    "ğœ†\n",
    "Î»: If \n",
    "ğœ†\n",
    "Î» is close to zero, the penalty is minimal, and the Lasso model behaves similarly to an OLS regression, with little to no feature selection.\n",
    "High \n",
    "ğœ†\n",
    "Î»: A large \n",
    "ğœ†\n",
    "Î» increases the penalty, leading to more coefficients being shrunk to zero, increasing feature selection but potentially introducing more bias into \n",
    "the model.\n",
    "Alpha (\n",
    "ğ›¼\n",
    "Î±): In the case of Elastic Net (a combination of Lasso and Ridge), \n",
    "ğ›¼\n",
    "Î± is a tuning parameter that controls the balance between Lasso and Ridge penalties.\n",
    "\n",
    "ğ›¼\n",
    "=\n",
    "1\n",
    "Î±=1: Pure Lasso regression.\n",
    "ğ›¼\n",
    "=\n",
    "0\n",
    "Î±=0: Pure Ridge regression.\n",
    "0 < \n",
    "ğ›¼\n",
    "Î± < 1: A mix of Lasso and Ridge penalties.\n",
    "Effect on Performance:\n",
    "\n",
    "Model Complexity: Higher values of \n",
    "ğœ†\n",
    "Î» result in simpler models with fewer features, which can be beneficial for interpretability but may lead to underfitting.\n",
    "Prediction Accuracy: There is often a trade-off between bias and variance. The optimal \n",
    "ğœ†\n",
    "Î» balances these to minimize the prediction error on unseen data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08923c0a-d88f-493a-863f-89b22e4861ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5: Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "Using Lasso Regression for Non-Linear Problems:\n",
    "\n",
    "Yes, Lasso Regression can be used for non-linear regression problems by transforming the input features. This can be done using techniques such as:\n",
    "Polynomial Features: By including polynomial terms of the original features (e.g., \n",
    "ğ‘¥\n",
    "2\n",
    "x \n",
    "2\n",
    " , \n",
    "ğ‘¥\n",
    "3\n",
    "x \n",
    "3\n",
    " ), Lasso can model non-linear relationships.\n",
    "Interaction Terms: Interaction terms between features (e.g., \n",
    "ğ‘¥\n",
    "1\n",
    "Ã—\n",
    "ğ‘¥\n",
    "2\n",
    "x \n",
    "1\n",
    "â€‹\n",
    " Ã—x \n",
    "2\n",
    "â€‹\n",
    " ) can be added to capture interactions between variables.\n",
    "Basis Expansions: Apply non-linear transformations to the features (e.g., log, exponential) to model more complex relationships.\n",
    "After transforming the features, Lasso regression can be applied as usual, with the regularization process selecting the most important\n",
    "non-linear terms.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66854879-d542-4ab9-a2fc-74a50beb92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
